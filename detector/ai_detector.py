import re
import numpy as np
from collections import Counter
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

class AITextDetector:
    """
    Detects if text is generated by AI using multiple heuristics
    and machine learning models.
    """
    
    def __init__(self, use_ml_model=False):
        self.use_ml_model = use_ml_model
        
        # AI-generated text often has these characteristics
        self.ai_patterns = {
            'repetitive_phrases': [
                'it is important to note',
                'it\'s worth noting',
                'in conclusion',
                'furthermore',
                'moreover',
                'however, it is important',
                'on the other hand'
            ],
            'generic_phrases': [
                'as an AI',
                'I don\'t have personal',
                'I cannot provide',
                'delve into',
                'leverage',
                'robust solution'
            ]
        }
        
        if use_ml_model:
            try:
                # Load pre-trained AI detection model roberta-base-openai-detector
                self.tokenizer = AutoTokenizer.from_pretrained(
                    "roberta-base-openai-detector"
                )
                self.model = AutoModelForSequenceClassification.from_pretrained(
                    "roberta-base-openai-detector"
                )
            except Exception as e:
                print(f"Could not load ML model: {e}")
                self.use_ml_model = False
    
    def detect(self, text):
        """
        Main detection method. Returns analysis results.
        """
        result = {
            'text_sample': text[:200] + '...' if len(text) > 200 else text,
            'is_ai_generated': False,
            'confidence': 0.0,
            'indicators': [],
            'scores': {}
        }
        
        # Heuristic-based detection
        perplexity_score = self._calculate_perplexity(text)
        burstiness_score = self._calculate_burstiness(text)
        pattern_score = self._check_ai_patterns(text)
        uniformity_score = self._check_sentence_uniformity(text)
        
        result['scores']['perplexity'] = perplexity_score
        result['scores']['burstiness'] = burstiness_score
        result['scores']['pattern_match'] = pattern_score
        result['scores']['uniformity'] = uniformity_score
        
        # Combine scores (weighted average)
        heuristic_score = (
            perplexity_score * 0.3 +
            burstiness_score * 0.3 +
            pattern_score * 0.2 +
            uniformity_score * 0.2
        )
        
        result['scores']['heuristic_total'] = heuristic_score
        
        # ML-based detection
        if self.use_ml_model:
            ml_score = self._ml_detection(text)
            result['scores']['ml_model'] = ml_score
            
            # Combine with heuristic score
            final_score = (heuristic_score * 0.4) + (ml_score * 0.6)
        else:
            final_score = heuristic_score
        
        result['confidence'] = final_score
        
        # Determine if AI-generated
        if final_score > 0.6:
            result['is_ai_generated'] = True
            result['indicators'].append('High probability of AI generation')
        
        return result
    
    def _calculate_perplexity(self, text):
        """
        Low perplexity indicates AI text (more predictable).
        Returns normalized score 0-1 (higher = more likely AI).
        """
        words = text.lower().split()
        if len(words) < 10:
            return 0.0
        
        # Calculate word frequency distribution
        word_freq = Counter(words)
        total_words = len(words)
        
        # Calculate entropy
        entropy = 0
        for count in word_freq.values():
            prob = count / total_words
            entropy -= prob * np.log2(prob)
        
        # Normalize (AI text typically has entropy between 3-5)
        # Human text typically has entropy 5-8
        if entropy < 4:
            return 0.8  # Likely AI
        elif entropy < 5:
            return 0.5
        else:
            return 0.2  # Likely human
    
    def _calculate_burstiness(self, text):
        """
        AI text has low burstiness (more uniform sentence structure).
        Returns score 0-1 (higher = more likely AI).
        """
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if len(sentences) < 3:
            return 0.0
        
        # Calculate sentence length variance
        lengths = [len(s.split()) for s in sentences]
        if not lengths:
            return 0.0
        
        mean_length = np.mean(lengths)
        std_length = np.std(lengths)
        
        # Low variance indicates AI text
        cv = std_length / mean_length if mean_length > 0 else 0
        
        # Human text typically has CV > 0.4
        if cv < 0.2:
            return 0.8  # Likely AI
        elif cv < 0.4:
            return 0.5
        else:
            return 0.2  # Likely human
    
    def _check_ai_patterns(self, text):
        """
        Check for common AI-generated phrases and patterns.
        Returns score 0-1 (higher = more likely AI).
        """
        text_lower = text.lower()
        pattern_count = 0
        
        # Check repetitive phrases
        for phrase in self.ai_patterns['repetitive_phrases']:
            if phrase in text_lower:
                pattern_count += 1
        
        # Check generic phrases
        for phrase in self.ai_patterns['generic_phrases']:
            if phrase in text_lower:
                pattern_count += 2  # Weight these higher
        
        # Check for overly formal language in informal context
        formal_words = ['furthermore', 'moreover', 'hence', 'thus', 'whereby']
        formal_count = sum(1 for word in formal_words if word in text_lower)
        
        total_score = (pattern_count * 0.15) + (formal_count * 0.1)
        return min(total_score, 1.0)
    
    def _check_sentence_uniformity(self, text):
        """
        AI text often has very uniform sentence structure.
        Returns score 0-1 (higher = more likely AI).
        """
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if len(sentences) < 3:
            return 0.0
        
        # Check starting words
        start_words = [s.split()[0].lower() if s.split() else '' 
                       for s in sentences]
        unique_starts = len(set(start_words))
        
        # AI text often has less variety in sentence starts
        variety_ratio = unique_starts / len(sentences)
        
        if variety_ratio < 0.5:
            return 0.7
        elif variety_ratio < 0.7:
            return 0.4
        else:
            return 0.1
    
    def _ml_detection(self, text):
        """
        Use machine learning model for detection.
        Returns score 0-1 (higher = more likely AI).
        """
        try:
            inputs = self.tokenizer(text, return_tensors="pt", 
                                   truncation=True, max_length=512)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                predictions = torch.softmax(outputs.logits, dim=-1)
                # Assuming class 1 is "AI-generated"
                ai_probability = predictions[0][1].item()
            
            return ai_probability
        except Exception as e:
            print(f"ML detection error: {e}")
            return 0.0
    
    def get_confidence_level(self, confidence):
        """Convert confidence score to readable level."""
        if confidence < 0.3:
            return 'LOW - Likely Human'
        elif confidence < 0.6:
            return 'MEDIUM - Uncertain'
        elif confidence < 0.8:
            return 'HIGH - Likely AI'
        else:
            return 'VERY HIGH - Almost Certainly AI'


# Example usage
if __name__ == '__main__':
    detector = AITextDetector(use_ml_model=False)
    
    # Test texts
    ai_text = """
    It is important to note that artificial intelligence has revolutionized 
    many industries. Furthermore, the advancement of machine learning has 
    enabled unprecedented capabilities. Moreover, it is worth noting that 
    these technologies continue to evolve rapidly.
    """
    
    human_text = """
    Hey! Just wanted to check if you're free this weekend. My friend is 
    having a BBQ and it'd be great if you could come. Let me know! Oh, 
    and bring chips if you can :)
    """
    
    for text, label in [(ai_text, "AI Sample"), (human_text, "Human Sample")]:
        print(f"\n--- {label} ---")
        result = detector.detect(text)
        print(f"AI Generated: {result['is_ai_generated']}")
        print(f"Confidence: {result['confidence']:.2f}")
        print(f"Level: {detector.get_confidence_level(result['confidence'])}")
        print(f"Scores: {result['scores']}")
        
